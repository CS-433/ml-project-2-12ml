{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Harness by EleutherAI to evaluate commonsense causal reasoning\n",
        "\n",
        "Original repo [here](https://github.com/EleutherAI/lm-evaluation-harness)"
      ],
      "metadata": {
        "id": "hKpcqvQqijOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq sqlitedict sacrebleu pycountry rouge-score pytablewriter\n",
        "!pip install -qqq transformers[sentencepiece] datasets evaluate\n",
        "!git clone https://github.com/EleutherAI/lm-evaluation-harness.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMCWIp1wT_oz",
        "outputId": "7cd86f1f-d244-42f3-b847-1f6b807c2176"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 118 kB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 54.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 106 kB 20.3 MB/s \n",
            "\u001b[?25h  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pycountry (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions:\n",
        "\n",
        "1. Open the file `lm-evaluation-harness/lm_eval/tasks/superglue.py` in a text editor (Colab natively supports editing files).\n",
        "\n",
        "2. To evaluate on e-CARE, edit lines 162 and 163 as follows:\n",
        "\n",
        "```\n",
        "DATASET_PATH = \"12ml/e-CARE\"\n",
        "DATASET_NAME = None\n",
        "```\n",
        "(We uploaded the e-CARE dataset to HuggingFace Hub for convenience).\n",
        "\n",
        "3. In the cell below, change `num_fewshot` as needed. Remove `--model_args pretrained=EleutherAI/gpt-neo-1.3B` to evaluate GPT-2."
      ],
      "metadata": {
        "id": "OK_-b3Nu1gnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd lm-evaluation-harness && python main.py --model gpt2 --model_args pretrained=EleutherAI/gpt-neo-1.3B --tasks copa --device 0 --num_fewshot 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1V7pEONXj_g",
        "outputId": "053dccb4-3464-46a8-ceb1-16d0e2677ff5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Tasks: ['copa']\n",
            "Using device '0'\n",
            "WARNING:datasets.builder:Found cached dataset super_glue (/root/.cache/huggingface/datasets/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n",
            "100% 3/3 [00:00<00:00, 61.32it/s]\n",
            "Running loglikelihood requests\n",
            "0it [00:00, ?it/s]\n",
            "{\n",
            "  \"results\": {\n",
            "    \"copa\": {\n",
            "      \"acc\": 0.74,\n",
            "      \"acc_stderr\": 0.04408440022768079\n",
            "    }\n",
            "  },\n",
            "  \"versions\": {\n",
            "    \"copa\": 0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"model\": \"gpt2\",\n",
            "    \"model_args\": \"pretrained=EleutherAI/gpt-neo-1.3B\",\n",
            "    \"num_fewshot\": 1,\n",
            "    \"batch_size\": null,\n",
            "    \"device\": \"0\",\n",
            "    \"no_cache\": false,\n",
            "    \"limit\": null,\n",
            "    \"bootstrap_iters\": 100000,\n",
            "    \"description_dict\": {}\n",
            "  }\n",
            "}\n",
            "gpt2 (pretrained=EleutherAI/gpt-neo-1.3B), limit: None, provide_description: False, num_fewshot: 1, batch_size: None\n",
            "|Task|Version|Metric|Value|   |Stderr|\n",
            "|----|------:|------|----:|---|-----:|\n",
            "|copa|      0|acc   | 0.74|±  |0.0441|\n",
            "\n"
          ]
        }
      ]
    }
  ]
}